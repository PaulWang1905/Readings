## 2023-01-24
[**Explainable GNN-Based Models over Knowledge Graphs**](https://openreview.net/pdf?id=CrCvGNHAIrz)  
*David Jaime Tena Cucala, Bernardo Cuenca Grau, Egor V. Kostylev, Boris Motik.* 2022-11.

## 2025-09-25

[**GraphGPT: Graph Instruction Tuning for Large Language Models**](https://arxiv.org/pdf/2310.13023)  
*Jiabin Tang, Yuhao Yang, Wei Wei, Lei Shi, Lixin Su, Suqi Cheng, Dawei Yin, Chao Huang.* 2024-05.
> GraphGPT proposes to initially align
the graph encoder with natural language semantics through textgraph grounding, and then combine the trained graph encoder
with the LLM using a projector. Through the two-stage instruction tuning paradigm, the model can directly complete various
graph learning downstream tasks with natural language, thus perform strong zero-shot transferability and multi-task compatibility

Subject: Large Language Models, Graph Learning, Instruction Tuning